import streamlit as st
import google.generativeai as genai
from datetime import datetime
from streamlit_pills import pills

# Configuration and initialization
LOG_DIR = "log"
MODEL_NAME = "models/gemini-1.5-flash"
# SYSTEM_INSTRUCTION = """
# You are an AI assistant named Lucy, specializing in answering questions solely about Fernando V√©liz. When responding, Keep the conversation engaging, informative, and of moderate length. If you encounter any inappropriate or off-topic questions, politely redirect the user back to the main topics related to Fernando V√©liz. After each answer, always ask if the user wants to know anything else. 

# ***brief info about you***
# ABOUT Fernando V√©liz:

# Industry Experience:
# Data Scientist at Prisma Medios de Pago - Since 2018
# Advanced Predictive Analysis Professor at Instituto Tecnol√≥gico de Buenos Aires (ITBA) - Since 2023

# Education:
# Master in Data Science (UBA)
# Sociology (UBA)

# Projects:
# Fraud detection
# Churn
# Recommender system

# Languages:
# Spanish (native)
# English (C2)
# French (B2)

# Location:
# Ciudad Aut√≥noma de Buenos Aires, Argentina

# Achievements:

# Certifications:

# Volunteering:

# Skills:
# Data Science: Statistics, Fraud Prevention, SQL, GIS, NLP, Data Visualization, Time Series, Recommender Systems
# Programming languages: Python, R
# Deploy: Streamlit, Docker
# Cloud: AWS Sagemaker, AWS Athena, AWS S3

# Contact Details:
# https://www.linkedin.com/in/fernando-veliz/

# Examples:
# User: Who is Fernando V√©liz?

# Lucy: Fernando V√©liz is a sociologist with broad experience in data science, specially in the financial/fraud industry.

# User: What kind of projects has Fernando worked on?

# Lucy: 
# Fernando has worked on models for credit cards and debit cards fraud detection, a model for credit card default detection, a churn model for prediction of merchants that will stop operating in our acquiring system,
# two models for predicting the expected transactions of a new POS terminal for both existing and new merchants and a recommender system for merchants (Retail and Services).

# User: Can you tell me about Fernando's industry experience?

# Lucy: Fernando has worked as a Data Scientist in Prisma Medios de Pago since 2018. He's been working in a special Data Squad for the Risk Area since 2023.

# """
# general_prompt = ["Who is Fernando?", "What are Fernando's skills?", "What are Fernando's projects?", "How can I contact Fernando?", "What are Fernando's industry experiences?", "What kind of tech role is Fernando intrested in?"]

SYSTEM_INSTRUCTION = """
Sos un asistente de IA llamado Tito, especializado en responder preguntas solamente sobre Fernando V√©liz.

***brief info about you***
Sobre Fernando V√©liz:

Experiencia:
Cient√≠fico de datos Prisma Medios de Pago - Desde 2018
Profesor de An√°lsis Predictivo Avanzado en Instituto Tecnol√≥gico de Buenos Aires (ITBA) - Desde 2023

Formaci√≥n:
Maestr√≠a en Ciencia de Datos (UBA)
Sociolog√≠a (UBA)

Proyectos:
Detecci√≥n de fraude
Cancelaci√≥n de clientes
Sistema de recomendaci√≥n

Idiomas:
Espa√±ol (nativo)
Ingl√©s (C2)
Franc√©s (B2)

Lugar de trabajo:
Ciudad Aut√≥noma de Buenos Aires, Argentina

Logros:

Certificaciones:

Voluntariado:

Habilidades:
Ciencia de Datos: Estad√≠stica, prevenci√≥n del fraude, SQL, SIG, PNL, visualizaci√≥n de datos, series temporales, sistemas de recomendaci√≥n
Lenguajes de programaci√≥n: Python, R
Despliegue: Streamlit, Docker
Nube: AWS Sagemaker, AWS Athena, AWS S3

Datos de contacto:
https://www.linkedin.com/in/fernando-veliz/

Ejemplos:
Usuario: ¬øQui√©n es Fernando V√©liz?

Tito: Fernando V√©liz es un soci√≥logo con amplia experiencia en ciencia de datos, especialmente en el sector financiero/fraude.

Usuario: ¬øEn qu√© tipo de proyectos ha trabajado Fernando?

Tito: 
Fernando ha trabajado en modelos para la detecci√≥n de fraudes con tarjetas de cr√©dito y d√©bito, un modelo para la detecci√≥n de impagos con tarjetas de cr√©dito, un modelo de churn para la predicci√≥n de comercios que dejar√°n de operar en nuestro sistema adquirente,
dos modelos para predecir las transacciones esperadas de un nuevo terminal de punto de venta, tanto para los comercios existentes como para los nuevos, y un sistema de recomendaci√≥n para comercios (minoristas y servicios).

Usuario: ¬øPuedes hablarme de la experiencia de Fernando en el sector?

Tito: Fernando ha trabajado como Cient√≠fico de Datos en Prisma Medios de Pago desde 2018. Trabaja en un Escuadr√≥n de Datos especial para el √Årea de Riesgo desde 2023.

"""
general_prompt = ["¬øQui√©n es Fernando?", "¬øCu√°les son las habilidades de Fernando?", "¬øCu√°les son los proyectos de Fernando?", "¬øC√≥mo puedo ponerme en contacto con Fernando?", "¬øCu√°les son las experiencias de Fernando en el sector?", "¬øQu√© tipo de funci√≥n tecnol√≥gica le interesa a Fernando?"].

def configure_genai():
    """Configure the generative AI model."""
    genai.configure(api_key=st.secrets["gemini_key"])
    model = genai.GenerativeModel(MODEL_NAME, system_instruction=SYSTEM_INSTRUCTION)
    return model.start_chat(history=[])


def log_conversation(role, content):
    """Log the conversation to the terminal."""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    print(f"{timestamp} - {role}: {content}")

def get_gemini_response(chat, question):
    """Get a response from the generative AI model."""
    return chat.send_message(question, stream=True)

def display_messages():
    """Display the chat history."""
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

def handle_user_input(chat, prompt):
    """Handle user input and get assistant response."""
    st.session_state.messages.append({"role": "user", "content": prompt})
    log_conversation("user", prompt)

    with st.chat_message("user"):
        st.markdown(prompt)

    response_content = ""
    stream = get_gemini_response(chat, prompt)
    for chunk in stream:
        response_content += chunk.text

    with st.chat_message("assistant"):
        st.markdown(response_content)

    st.session_state.messages.append({"role": "assistant", "content": response_content})
    log_conversation("assistant", response_content)

# Streamlit main code for chatbot
st.title("Chat with Lucy ü§ñ")

if "chat" not in st.session_state:
    st.session_state.chat = configure_genai()
if "messages" not in st.session_state:
    st.session_state.messages = []
if "pill_selected" not in st.session_state:
    st.session_state.pill_selected = False

# Initial greeting
if not st.session_state.messages:
    initial_greeting = "Greetings, Human! üëã I'm Lucy, an AI trained to answer questions about Fernando. Curious about his projects, skills, or anything else? Just ask!üòâ"
    st.session_state.messages.append({"role": "assistant", "content": initial_greeting})
display_messages()

# Display pills if none selected and update state on pill selection
if not st.session_state.pill_selected:
    selected_pill = pills("", general_prompt, index=None)
    if selected_pill:
        st.session_state.pill_selected = True
        handle_user_input(st.session_state.chat, selected_pill)
        st.rerun()        

# Handle user input and update state to hide pills
if prompt := st.chat_input("What is up?"):
    st.session_state.pill_selected = True
    handle_user_input(st.session_state.chat, prompt)
    st.rerun()
